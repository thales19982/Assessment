{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a5b02898-beac-4417-99da-6c26170209f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "f0e7d840-2697-4b92-aa2f-245738b5cfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions that are used throughout the project \n",
    "def call_data(name,columns_dropped):\n",
    "\n",
    "#Reading the documento CSV\n",
    "    db = pd.read_csv(name)\n",
    "\n",
    "# Drop the columns which are gonna be unecessary to the analysis\n",
    "    db.drop(db.columns[columns_dropped],axis=1,inplace=True)\n",
    "    return db\n",
    "\n",
    "#Function to drop duplicates and NaN\n",
    "def drop_clean_table(name_table,columns_to_drop_duplicate,columns_to_drop_NaN):\n",
    "    name_table.drop_duplicates(subset = columns_to_drop_duplicate, inplace=True)\n",
    "\n",
    "#Drop NaN values which is not interesting for me \n",
    "    name_table.dropna(subset = columns_to_drop_NaN,inplace=True)\n",
    "    return name_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "d46a77e5-5ef0-4153-9418-dffe629a9075",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_date = call_data(\"olist_orders_dataset.csv\",[1,3,4,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "e289c0de-c19b-4256-abad-2f177d22a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting for deliveries completed \n",
    "order_date = order_date[order_date[\"order_status\"]==\"delivered\"]\n",
    "\n",
    "# Disconsider rows which there is no products departure and arrival dates (Difference: from 96478 to 96469)\n",
    "order_date.dropna(subset=['order_delivered_carrier_date', 'order_delivered_customer_date'],inplace=True)\n",
    "\n",
    "#Converting the dates columns into Series(datetimes type) and subtracting them \n",
    "date_departure = pd.to_datetime(order_date[\"order_delivered_carrier_date\"])\n",
    "date_arrival = pd.to_datetime(order_date[\"order_delivered_customer_date\"])\n",
    "time_delay = (date_arrival - date_departure) / np.timedelta64(1,\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "4b70aca9-b11c-4e2b-ac47-636319da481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the Series into DataFrame back\n",
    "date_merged = order_date.merge(time_delay.rename(\"Delivery Delay\"),left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "62729898-f535-458d-bc24-eaa3c9f75f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set index to merge with the other DF(seller_order) which there is the same data columns \n",
    "date_merged.set_index(\"order_id\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "5bab3ddc-1515-4dc0-8bfd-4e07846ee943",
   "metadata": {},
   "outputs": [],
   "source": [
    "seller_state = call_data(\"olist_sellers_dataset.csv\",[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "c98653a5-92ca-4a8d-b0f8-944a732954e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying if there is no duplicates or NaN by the function\n",
    "seller_state =drop_clean_table(seller_state,[\"seller_id\"],[\"seller_id\",\"seller_state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "003bc3fd-752a-4f67-a3c7-1c37de173245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set index to merge with the other DF(seller_order) which there is the same data columns \n",
    "seller_state.set_index(\"seller_id\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "976bac0c-5378-490a-a3fb-7a3d729d5c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the function to call the DF\n",
    "seller_order = call_data(\"olist_order_items_dataset.csv\",[1,2,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "63787d3c-6688-4355-8f04-9231e7c76062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the function to clean the DF\n",
    "seller_order =drop_clean_table(seller_order,[\"order_id\",\"seller_id\"],[\"order_id\",\"seller_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "237cc1ca-433a-4dea-9048-0b93ffa1150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index to merge with the other DF(seller_state) which there is the same data columns \n",
    "seller_order.set_index(\"seller_id\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "e2b444b3-8de0-46b8-955f-ec0c48f3fc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the 2 DFs to get the relation between the order and where its departuring \n",
    "seller_order = seller_order.merge(seller_state,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "bac2252b-2c7f-426a-9591-3f8381f83fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set index to merge with the other DF(date_merged) which there is the same data columns \n",
    "seller_order.set_index(\"order_id\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "05594459-08f5-482d-9937-3018cc5a3569",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_time = date_merged.merge(seller_order,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "df62eff6-8ff0-4584-a7b5-d513a4b77d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Delivery Orders  Delivery Delay(Days)\n",
      "seller_state                                       \n",
      "RS                       1964              8.064388\n",
      "MS                         49              8.098366\n",
      "RN                         51              8.716393\n",
      "SP                      69395              9.095651\n",
      "RJ                       4229              9.225426\n",
      "PB                         35              9.371992\n",
      "DF                        808              9.519663\n",
      "MG                       7745              9.621394\n",
      "PR                       7555              9.938253\n",
      "PA                          8              9.954369\n",
      "SE                          9             10.292127\n",
      "GO                        451             10.298114\n",
      "BA                        550             10.519742\n",
      "ES                        310             10.534219\n",
      "SC                       3608             10.597436\n",
      "PE                        403             10.608309\n",
      "MT                        136             11.434185\n",
      "PI                         11             12.005422\n",
      "MA                        389             12.894393\n",
      "CE                         87             14.403983\n",
      "RO                         14             14.962379\n",
      "AM                          3             44.410799\n"
     ]
    }
   ],
   "source": [
    "#Counting the number of orders for each state\n",
    "delay_orders = place_time.groupby([\"seller_state\"])[\"Delivery Delay\"].agg(np.mean)\n",
    "num_orders_place = place_time.groupby([\"seller_state\"]).count()\n",
    "\n",
    "\n",
    "# If i needed just the delivery orders i would create a DF based on the Series using dictionaries as below in order to work \n",
    "# easily with the DF. However, i want to get more info so i merge the Series into a DF using concat and generate a DF needed automatically \n",
    "#Create a DF based on the Series already created \n",
    "#delay_orders_df = pd.DataFrame({'States':delay_orders.index, 'Delivery Delay':delay_orders.values})\n",
    "\n",
    "# Prepare the DF to merge to another \n",
    "num_orders_place.drop(num_orders_place.columns[[1,2,3,4]],axis=1,inplace=True)\n",
    "\n",
    "# Merge the Series into the DF to get all the info that i need in one table \n",
    "delay_orders_delivery = pd.concat([num_orders_place,delay_orders],axis=1)\n",
    "\n",
    "# Name the columns\n",
    "delay_orders_delivery.columns = [\"Delivery Orders\",\"Delivery Delay(Days)\"]\n",
    "\n",
    "delay_orders_delivery = delay_orders_delivery.sort_values(by = [\"Delivery Delay(Days)\",\"Delivery Orders\"], ascending= [True,False])\n",
    "print(delay_orders_delivery)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
